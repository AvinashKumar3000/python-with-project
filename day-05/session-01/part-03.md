# webscraping
Here is a **clean, simple, exam-friendly Web Scraping Cheat Sheet for Python** â€” perfect for fast revision.

---

# ğŸŒ **Python Web Scraping Cheat Sheet**

---

# âœ… **1. Install Required Libraries**

```bash
pip install requests
pip install beautifulsoup4
```

---

# âœ… **2. Import Libraries**

```python
import requests
from bs4 import BeautifulSoup
```

---

# ğŸš€ **3. Fetch a Webpage**

```python
url = "https://example.com"
response = requests.get(url)

html = response.text   # page source
```

---

# ğŸ¥£ **4. Parse HTML using BeautifulSoup**

```python
soup = BeautifulSoup(html, "html.parser")
```

---

# ğŸ” **5. Finding Elements**

### **Find first match**

```python
title = soup.find("h1")
```

### **Find all matches**

```python
links = soup.find_all("a")
```

### **Find by class**

```python
items = soup.find_all("div", class_="product")
```

### **Find by id**

```python
box = soup.find(id="main")
```

---

# ğŸ”— **6. Extracting Text & Attributes**

### **Get text**

```python
title_text = title.get_text()
```

### **Get attribute (href, src, etc.)**

```python
link = soup.find("a")["href"]
```

---

# ğŸ“„ **7. Extract All Links**

```python
all_links = [a["href"] for a in soup.find_all("a", href=True)]
```

---

# ğŸ“· **8. Extract All Images**

```python
images = [img["src"] for img in soup.find_all("img")]
```

---

# ğŸ§¹ **9. Cleaning Extracted Data**

```python
text = title.get_text(strip=True)
```

---

# ğŸ”„ **10. Loop Through Products Example**

```python
products = soup.find_all("div", class_="product")

for p in products:
    name = p.find("h2").get_text(strip=True)
    price = p.find("span", class_="price").get_text(strip=True)
    print(name, price)
```

---

# ğŸ§¾ **11. Save Scraped Data to CSV**

```python
import csv

with open("data.csv", "w", newline="") as f:
    writer = csv.writer(f)
    writer.writerow(["Name", "Price"])
    writer.writerows(data)
```

---

# âš ï¸ **12. Always Check robots.txt**

Example:

```
https://example.com/robots.txt
```

---

# ğŸš« **13. Don't Spam Requests**

```python
import time
time.sleep(1)  # wait 1 sec between requests
```

---

# ğŸ› ï¸ **14. Handle Errors**

```python
try:
    response = requests.get(url, timeout=5)
    response.raise_for_status()
except Exception as e:
    print("Error:", e)
```

---

# â­ **15. Useful Tips**

âœ” Use browser â€œInspect Elementâ€ to find tags
âœ” Use `.strip()` to clean text
âœ” Use `soup.select("css-selector")` for CSS-style querying
âœ” Some websites block scraping â†’ use headers or proxies
